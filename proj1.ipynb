{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proj1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShainaBagri/ClassifyDocumentTopics/blob/main/proj1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu-zBj8yirhF",
        "outputId": "bfe376c7-ebc2-4c55-a5ce-70b2bd6e58f2"
      },
      "source": [
        "!wget 'http://users.csc.calpoly.edu/~foaad/proj1F21_files.zip'\n",
        "!unzip 'proj1F21_files.zip'"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-20 19:55:41--  http://users.csc.calpoly.edu/~foaad/proj1F21_files.zip\n",
            "Resolving users.csc.calpoly.edu (users.csc.calpoly.edu)... 129.65.128.20\n",
            "Connecting to users.csc.calpoly.edu (users.csc.calpoly.edu)|129.65.128.20|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 129006 (126K) [application/zip]\n",
            "Saving to: ‘proj1F21_files.zip.1’\n",
            "\n",
            "proj1F21_files.zip. 100%[===================>] 125.98K   545KB/s    in 0.2s    \n",
            "\n",
            "2021-10-20 19:55:42 (545 KB/s) - ‘proj1F21_files.zip.1’ saved [129006/129006]\n",
            "\n",
            "Archive:  proj1F21_files.zip\n",
            "replace proj1F21_files/proj1F21_1412_A.html? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: proj1F21_files/proj1F21_1412_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_1412_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_1422_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_1422_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_1483_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_1483_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_1794_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_1794_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_1901_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_1901_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2404_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2404_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2422_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2422_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2509_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2509_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2592_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2592_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2605_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2605_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2925_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2925_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3061_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3061_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3363_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3363_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3453_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3453_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3490_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3490_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3509_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3509_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3550_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3550_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3618_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3618_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3647_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3647_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3928_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3928_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3942_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3942_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_4001_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_4001_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_4079_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_4079_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6218_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6218_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6388_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6388_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6533_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6533_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6585_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6585_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6728_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6728_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6737_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6737_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_8630_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_8630_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_8842_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_8842_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_8980_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_8980_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_9348_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_9348_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_9578_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_9578_B.html  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD5hswpu09YW",
        "outputId": "0054d1d3-6bef-4001-cc33-773cfd2607ca"
      },
      "source": [
        "!pip install html2text"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: html2text in /usr/local/lib/python3.7/dist-packages (2020.1.16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsfKLCZA28NW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b4b27d-4833-44a4-8632-0ed456992808"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# from nltk import PunktSentenceTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import html2text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "random.seed(123)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS1V5EDI5ZXi"
      },
      "source": [
        "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "def fixRaw(text):\n",
        "  newText = \"\"\n",
        "  for p in re.split('\\n\\n+', text):\n",
        "    newText = newText + p.replace('\\n', ' ').strip() + '\\n'\n",
        "  return newText\n",
        "\n",
        "def tokenizeText(text):\n",
        "  goodParas = []\n",
        "  for para in re.split('\\n\\n+', text):\n",
        "    sents = sent_tokenizer.tokenize(para.replace('\\n', ' ').strip())\n",
        "    goodSents = []\n",
        "    for sent in sents:\n",
        "      # TODO: lemmatize / convert contractions here?\n",
        "      words = [word.lower() for word in nltk.word_tokenize(sent)]\n",
        "      goodSents.append(words)\n",
        "    \n",
        "    goodParas.append(goodSents)\n",
        "      \n",
        "  return goodParas\n",
        "\n",
        "def extractFeaturesDoc(tokText, tfidf):\n",
        "  # def dummy(x):\n",
        "  #   return x\n",
        " \n",
        "  features = {}\n",
        "\n",
        "  # dummy data\n",
        "  features['len'] = len(tokText)\n",
        "\n",
        "  # Keep at end\n",
        "  features['tfidf'] = tfidf\n",
        "\n",
        "  return features"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HkMttbDh718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21960822-ae82-4e24-853b-dd9ae264c4dc"
      },
      "source": [
        "dir = './proj1F21_files/'\n",
        "# docs = pd.DataFrame(columns=['author', 'subject', 'rawText'])\n",
        "docs = []\n",
        "for document in os.listdir(dir):\n",
        "  dict = {}\n",
        "  docName = document.split(\"_\")\n",
        "  dict['author'] = docName[1]\n",
        "  dict['subject'] = docName[2][0]\n",
        "  with open(dir + document) as f:\n",
        "    dict['htmlText'] = f.read()\n",
        "    dict['rawText'] = html2text.html2text(dict['htmlText'])\n",
        "    dict['fixedRawText'] = fixRaw(dict['rawText'])\n",
        "    # tokenize \n",
        "    dict['tokenizedText'] = tokenizeText(dict['rawText']) \n",
        "\n",
        "  docs.append(dict)\n",
        "\n",
        "# split into training and test sets\n",
        "random.shuffle(docs)\n",
        "split = int(len(docs) *0.8)\n",
        "test_set = pd.DataFrame(docs[split:])\n",
        "training_set = pd.DataFrame(docs[:split])\n",
        "\n",
        "# print(training_set['htmlText'][0])\n",
        "# print(training_set['rawText'][0])\n",
        "print(training_set['tokenizedText'][0])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[['evidenced', 'by', 'physicists', 'isaac', 'newton', 'and', 'albert', 'einstein', ',', 'or', 'mathematicians', 'john', 'von', 'neumann', 'and', 'alan', 'turing', ',', 'the', 'mind', 'can', 'venture', 'the', 'galaxy', 'without', 'ever', 'moving', ',', 'discover', 'properties', 'still', 'widely', 'used', 'far', 'into', 'the', 'future', ',', 'create', 'a', 'game', 'that', 'can', 'be', 'used', 'to', 'study', 'economics', ',', 'or', 'save', 'countless', 'of', 'lives', '.'], ['it', '’', 's', 'no', 'exception', 'for', 'mathematician', 'john', 'forbes', 'nash', 'jr.', ',', 'who', ',', 'during', 'his', 'lifetime', ',', 'created', 'the', 'nash', 'equilibrium', ',', 'a', 'solution', 'concept', ',', 'or', 'a', 'prediction', 'for', 'how', 'a', 'game', 'will', 'be', 'played', ',', 'for', 'two', 'or', 'more', 'player', 'non-cooperative', 'games', 'in', 'game', 'theory', ',', 'which', 'later', 'landed', 'him', 'a', 'nobel', 'prize', 'in', 'economics', '.'], ['born', 'in', 'bluefield', ',', 'west', 'virginia', 'on', 'june', '13th', ',', '1928', 'and', 'died', 'in', 'monroe', 'township', ',', 'new', 'jersey', 'on', 'march', '23rd', ',', '2015', ',', 'john', 'nash', 'jr.', 'has', 'written', 'multiple', 'heavily', 'influential', 'papers', 'in', 'mathematics', 'while', 'dealing', 'with', 'his', 'schizophrenia', 'and', 'pressuring', 'marriage', '.'], ['nash', 'lived', 'with', 'his', 'sister', 'and', 'mother', ',', 'nicknamed', '“', 'virginia', '”', ',', 'and', 'later', 'moved', 'out', 'to', 'attend', 'carnegie', 'institute', 'of', 'technology', ',', 'where', 'he', 'was', 'recognized', 'and', 'accepted', 'into', 'princeton', 'university', '.'], ['his', 'time', 'at', 'princeton', 'would', 'later', 'become', 'one', 'of', 'the', 'most', 'important', 'time', 'periods', 'in', 'his', 'life', ',', 'as', 'it', 'was', 'where', 'he', 'wrote', 'his', 'nobel', 'prize', 'winning', 'paper', 'on', 'the', 'nash', 'equilibrium', '.']], [['as', 'opposed', 'to', 'other', 'mathematicians', ',', 'who', 'would', 'stray', 'away', 'from', 'a', 'problem', 'if', 'it', 'took', 'too', 'long', 'to', 'solve', ',', 'nash', 'could', 'spend', 'years', 'concentrating', 'on', 'a', 'problem', 'until', 'he', 'is', 'sure', 'he', 'has', 'the', 'solution', '.'], ['john', 'von', 'neumann', 'was', 'the', 'complete', 'opposite', 'of', 'nash', '.'], ['neumann', 'is', 'considered', 'to', 'be', 'one', 'of', 'the', 'greatest', 'mathematicians', 'at', 'the', 'turn', 'of', 'the', '20th', 'century', '.'], ['in', 'seconds', ',', 'he', 'could', 'solve', 'numerous', 'famous', 'mathematical', 'problems', 'in', 'his', 'head', '.'], ['his', 'work', 'in', 'economics', 'and', 'creation', 'of', 'a', 'new', 'field', ',', 'named', 'game', 'theory', ',', 'was', 'directly', 'defied', 'by', 'nash', ',', 'who', 'claimed', 'there', 'was', 'multiple', 'holes', 'in', 'the', 'theory', ',', 'all', 'of', 'which', 'he', 'could', 'fix', '.']], [['all', 'those', 'traits', 'would', 'later', 'become', 'the', 'building', 'blocks', 'of', 'nash', '’', 's', 'personality', 'and', 'his', 'defensive', 'nature', '.'], ['those', 'qualities', 'in', 'the', '1950s', 'would', 'also', 'influence', 'how', 'nash', 'would', 'later', 'tackle', 'well-known', 'difficult', 'problems', 'with', 'little', 'outside', 'help', '.'], ['in', 'the', '1940s', 'and', '1950s', ',', 'there', 'were', 'an', 'abundance', 'of', 'problems', 'and', 'unproven', 'conjectures', 'for', 'any', 'bright', 'and', 'ambitious', 'mathematician', 'to', 'tackle', 'such', 'as', 'nash', '.'], ['admittedly', ',', 'his', 'own', 'inability', 'to', 'admit', 'defeat', 'and', 'his', 'arrogance', 'would', 'later', 'come', 'back', 'and', 'haunt', 'him', 'as', 'well', '.'], ['his', 'arrogant', 'nature', 'is', 'most', 'prominent', 'when', 'he', 'refused', 'to', 'marry', 'eleanor', ',', 'the', 'women', 'who', 'was', 'bearing', 'his', 'child', ',', 'due', 'to', 'him', 'deeming', 'her', 'as', 'someone', 'that', 'was', 'not', 'worthy', 'or', 'unequal', 'to', 'him', '.'], ['any', 'account', 'of', 'nash', '’', 's', 'intent', 'whether', 'or', 'not', 'to', 'marry', 'eleanor', 'was', 'never', 'confirmed', 'to', 'be', 'true', '.'], ['a', 'likely', 'reason', 'was', 'his', 'obsession', 'with', 'class', ',', 'similar', 'to', 'his', 'father', '’', 's', ',', 'where', 'he', 'believed', 'that', 'eleanor', '’', 's', 'social', 'inferiority', 'would', 'have', 'been', 'difficult', 'for', 'her', 'to', 'mingle', 'with', 'other', 'wives', 'of', 'the', 'cambridge', 'mathematical', 'community', '.'], ['when', 'their', 'son', ',', 'john', 'david', 'stier', ',', 'was', 'born', ',', 'eleanor', 'had', 'to', 'give', 'him', 'up', 'to', 'foster', 'care', ',', 'which', 'drove', 'her', 'mad', '.'], ['her', 'son', '’', 's', 'leave', 'made', 'her', 'believe', 'that', 'nash', '“', 'left', 'all', 'the', 'anguish', 'and', 'the', 'worry', 'to', 'her', 'and', 'gave', 'no', 'sign', 'that', 'he', 'understood', ',', 'even', 'remotely', ',', 'what', 'such', 'a', 'separation', 'might', 'mean', 'for', 'a', 'mother', 'or', 'her', 'child', '”', '.'], ['of', 'course', 'this', 'was', 'what', 'made', 'nash', '’', 's', 'life', 'most', 'despicable', ',', 'his', 'nonexistent', 'capacity', 'for', 'empathy', '.'], ['nash', 'would', 'end', 'up', 'losing', 'multiple', 'relationships', ',', 'friendships', ',', 'and', 'make', 'numerous', 'enemies', 'in', 'his', 'lifetime', '.']], [['although', 'nash', 'was', 'childish', 'at', 'times', ',', 'his', 'arrogance', 'and', 'headstrong', 'will', 'was', 'still', 'what', 'made', 'his', 'life', 'admirable', '.'], ['ambrose', 'once', 'challenged', 'nash', 'to', 'solve', 'the', 'embedding', 'problem', 'for', 'manifolds', ',', 'a', 'notoriously', 'difficult', 'problem', 'that', 'had', 'been', 'around', 'since', 'riemann', ',', 'a', '17th', 'century', 'mathematician', ',', 'first', 'proposed', 'it', '.'], ['when', 'nash', 'gave', 'his', 'lecture', 'two', 'years', 'after', 'the', 'bet', 'with', 'ambrose', ',', 'he', 'made', 'it', 'very', 'clear', 'that', 'he', 'solved', 'the', 'problem', 'merely', 'because', 'of', 'the', 'bet', '.'], ['this', 'speaks', 'volumes', 'about', 'who', 'nash', 'is', 'as', 'a', 'person', ',', 'a', 'mathematician', 'who', 'saw', '“', 'mathematics', 'not', 'as', 'a', 'grand', 'scheme', ',', 'but', 'as', 'a', 'collection', 'of', 'challenging', 'problems', '”', '.'], ['nash', 'didn', '’', 't', 'call', 'himself', 'a', 'game', 'theorist', ',', 'or', 'a', 'topologist', ',', 'but', 'rather', 'a', 'mathematician', 'who', 'went', 'to', 'other', 'fields', 'that', 'practically', 'nobody', 'had', 'achieved', 'anything', '.'], ['he', 'would', 'take', 'this', 'opportunity', 'to', 'find', 'any', 'problems', 'that', 'piqued', 'his', 'interest', '.'], ['the', 'embedding', 'problem', 'proved', 'itself', 'to', 'be', 'quite', 'a', 'challenge', 'for', 'nash', ',', 'but', 'he', 'never', 'gave', 'up', '.'], ['solving', 'such', 'an', 'infamous', 'problem', 'also', 'took', 'a', 'lot', 'of', 'courage', 'as', 'he', 'brought', 'himself', 'into', 'the', 'realm', 'where', 'people', 'believed', 'what', 'was', 'possible', 'and', 'what', 'wasn', '’', 't', ',', 'and', 'directly', 'challenged', 'them', '.'], ['after', 'he', 'succeeded', 'in', 'solving', 'the', 'problem', ',', 'ambrose', ',', 'being', 'the', 'fine', 'mathematician', 'he', 'is', ',', 'made', '“', 'his', 'applause', '…', 'as', 'loud', 'or', 'louder', 'than', 'anyone', 'else', '’', 's', '”', '.'], ['moving', 'past', 'his', 'childish', 'traits', ',', 'one', 'has', 'to', 'truly', 'admire', 'what', 'a', 'brilliant', 'mind', 'nash', 'has', 'when', 'given', 'the', 'opportunity', 'to', 'see', 'it', 'in', 'action', '.']], [['as', 'brilliant', 'as', 'nash', 'was', ',', 'his', 'social', 'iq', 'was', 'still', 'very', 'much', 'lacking', '.'], ['one', 'of', 'the', 'biggest', 'mistakes', 'he', 'made', 'was', 'not', 'only', 'that', 'he', 'refused', 'to', 'marry', 'eleanor', ',', 'but', 'that', 'he', 'began', 'to', 'date', 'another', 'woman', 'after', 'he', 'left', 'her', '.'], ['that', 'decision', 'would', 'later', 'come', 'back', 'and', 'haunt', 'him', 'when', 'his', 'father', 'calls', 'and', 'tells', 'him', 'of', 'his', 'knowledge', 'of', 'nash', '’', 's', 'son', '.'], ['eleanor', 'has', 'gotten', 'a', 'lawyer', 'and', 'demanded', 'child', 'support', 'payments', ',', 'but', 'nash', 'still', '“', 'was', 'inclined', 'to', 'refuse', 'to', 'pay', '”', '.'], ['his', 'decision', 'shows', 'who', 'he', 'really', 'is', 'as', 'a', 'person', ',', 'which', 'is', 'a', 'man', 'who', 'won', '’', 't', 'do', 'the', 'right', 'thing', 'because', 'he', 'believes', 'it', 'to', 'not', 'be', 'worth', 'his', 'time', '.']], [['normally', 'people', 'would', 'say', 'a', 'hero', 'is', 'someone', 'who', 'saves', 'lives', 'or', 'makes', 'personal', 'sacrifices', 'for', 'the', 'benefit', 'of', 'others', '.'], ['a', 'hero', 'might', 'not', 'necessarily', 'be', 'known', 'nationally', 'or', 'internationally', 'such', 'as', 'a', 'celebrity', ',', 'but', 'still', 'famous', 'in', 'their', 'own', 'right', ',', 'either', 'to', 'themselves', 'or', 'those', 'close', 'to', 'them', '.'], ['john', 'forbes', 'nash', 'jr.', 'was', 'undoubtedly', 'a', 'hero', '.']], []]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHNeMvbIsyoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754431da-126f-4213-f7ff-fb9d5e8aa0ea"
      },
      "source": [
        "print(training_set['rawText'][0])\n",
        "print(training_set['fixedRawText'][0])"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    While I haven’t had a ton of experiences to shape myself into a leader yet, I know that one leader I look up to a lot is Steve Jobs. While Steve Jobs wasn’t the best person in the world and did/said a lot of mean and hurtful things to other people, I think there were certain aspects of his leadership style that I really admire and would like to emulate. There are many leadership traits that Steve Jobs embodied, and I would like to embody as well. I think the most significant three traits were Decisiveness, Tact, and Endurance.  \n",
            "As Apple’s CEO, Steve Jobs constantly made decisions. He made decisions to\n",
            "determine the aesthetics of Apple products, what kinds of markets they should\n",
            "target, very small details of product design, as well as many other decisions.\n",
            "The majority of the decisions Steve Jobs made were made very quickly, and most\n",
            "of the time, were also the best decisions to be made. I am reading his\n",
            "biography right now, and there are multiple accounts of people coming to work\n",
            "for Apple and being astounded to find that Steve Jobs would make decisions to\n",
            "change fundamental features of a product on a whim. At the corporations these\n",
            "people worked at beforehand, they would have to go through weeks of PowerPoint\n",
            "presentations to convince old board members that their product changes were\n",
            "the right ones to make. This was not the case with Jobs. If there was an\n",
            "important change that needed to be made, Jobs would be able to see the\n",
            "importance of the change and decide to make it at the snap of his fingers. I\n",
            "would like to embody Jobs’ ability to make decisions both accurately and\n",
            "quickly. I believe it is the ability to make the right decisions at the right\n",
            "times that will determine a leader’s ability to create great products. Not\n",
            "only was Jobs decisive though, but he also showed a great deal of Tact.\n",
            "\n",
            "    Steve Jobs was a very tactful CEO. In the 80s, Jobs was ousted from his role as Apple’s CEO, and for a while didn’t know what he would do. He eventually started a new computer company named NeXT, and also helped start Pixar, which would go on to create Toy Story under his leadership. Jobs was very tactful at Pixar, as the company actually started when Jobs bought Lucasfilm’s computer graphics division because Jobs saw the intersection of the arts and computing as the future. Jobs bought Lucasfilm’s graphics division for $5 million, Toy Story had a box office of $373 million. Jobs was even more tactful with NeXT, as he designed his software to work on Apple computers, and when Apple was looking for a company to help them build their own software after some struggles, they ended up buying NeXT. This eventually put Jobs back into his role as Apple’s CEO leading to Apple’s great success with the iPod and iPhone. Not only was Jobs tactful, he also showed a great deal of endurance.\n",
            "\n",
            "    The ability to focus on something intensely for great periods of time was often noted as one of Steve Jobs’ signature traits. Jobs could endure long hours of focusing on the same problem, which led him to come up with great solutions to large business problems. I believe this is a trait I have shown in individual CS settings but have not yet shown in a leadership setting. Since I cannot think of any standout times, I have shown leadership traits in leadership settings (since CS work is often individual) I will just talk about an individual experience. This past fall quarter I took the class CPE 357, which is known as the hardest or one of the hardest CS classes at Cal Poly. In this class we have 20 labs and 7 projects in 10 weeks, in most CS classes you have 9 labs and 3 projects in 10 weeks. This class was designed to push students to their limits, and weed out the ones that couldn’t handle CS. This class pushed me past my limit. Before taking this class I always felt that I naturally had a poor work ethic and a lack of focus and discipline on my assignments. This class showed me that my potential for endurance can only be known by pushing myself as hard as I can. There were points in this class where I would have to pull 14-hour days for weeks straight. I would get up at 7AM, start coding, and not stop until 12AM when I would go back to bed (I would take breaks to eat which probably removed ~4-5 hours of work time). This was the hardest I have ever worked on something in my life. While this semi-deteriorated a lot of relationships in my life as well as my physical health a bit, it showed me that I am capable of endurance greater than I had known before. With enough hard work and effort, I was able to finish near the top of my class and earned an A-. Because of this experience I now have a better idea of what it takes to focus and endure suffering and want to take this understanding to leadership roles in my future.\n",
            "\n",
            "    To summarize, three of the leadership traits Steve Jobs embodied that I want to embody as well were Decisiveness, Tact, and Endurance. Steve Jobs could make decisions on a whim, strategize to put himself in positions for success, and could focus and endure for great amounts of time. While Steve Jobs was not a great person, I hope that with enough effort and leadership experience, I can embody these traits as well.\n",
            "\n",
            "\n",
            "While I haven’t had a ton of experiences to shape myself into a leader yet, I know that one leader I look up to a lot is Steve Jobs. While Steve Jobs wasn’t the best person in the world and did/said a lot of mean and hurtful things to other people, I think there were certain aspects of his leadership style that I really admire and would like to emulate. There are many leadership traits that Steve Jobs embodied, and I would like to embody as well. I think the most significant three traits were Decisiveness, Tact, and Endurance.   As Apple’s CEO, Steve Jobs constantly made decisions. He made decisions to determine the aesthetics of Apple products, what kinds of markets they should target, very small details of product design, as well as many other decisions. The majority of the decisions Steve Jobs made were made very quickly, and most of the time, were also the best decisions to be made. I am reading his biography right now, and there are multiple accounts of people coming to work for Apple and being astounded to find that Steve Jobs would make decisions to change fundamental features of a product on a whim. At the corporations these people worked at beforehand, they would have to go through weeks of PowerPoint presentations to convince old board members that their product changes were the right ones to make. This was not the case with Jobs. If there was an important change that needed to be made, Jobs would be able to see the importance of the change and decide to make it at the snap of his fingers. I would like to embody Jobs’ ability to make decisions both accurately and quickly. I believe it is the ability to make the right decisions at the right times that will determine a leader’s ability to create great products. Not only was Jobs decisive though, but he also showed a great deal of Tact.\n",
            "Steve Jobs was a very tactful CEO. In the 80s, Jobs was ousted from his role as Apple’s CEO, and for a while didn’t know what he would do. He eventually started a new computer company named NeXT, and also helped start Pixar, which would go on to create Toy Story under his leadership. Jobs was very tactful at Pixar, as the company actually started when Jobs bought Lucasfilm’s computer graphics division because Jobs saw the intersection of the arts and computing as the future. Jobs bought Lucasfilm’s graphics division for $5 million, Toy Story had a box office of $373 million. Jobs was even more tactful with NeXT, as he designed his software to work on Apple computers, and when Apple was looking for a company to help them build their own software after some struggles, they ended up buying NeXT. This eventually put Jobs back into his role as Apple’s CEO leading to Apple’s great success with the iPod and iPhone. Not only was Jobs tactful, he also showed a great deal of endurance.\n",
            "The ability to focus on something intensely for great periods of time was often noted as one of Steve Jobs’ signature traits. Jobs could endure long hours of focusing on the same problem, which led him to come up with great solutions to large business problems. I believe this is a trait I have shown in individual CS settings but have not yet shown in a leadership setting. Since I cannot think of any standout times, I have shown leadership traits in leadership settings (since CS work is often individual) I will just talk about an individual experience. This past fall quarter I took the class CPE 357, which is known as the hardest or one of the hardest CS classes at Cal Poly. In this class we have 20 labs and 7 projects in 10 weeks, in most CS classes you have 9 labs and 3 projects in 10 weeks. This class was designed to push students to their limits, and weed out the ones that couldn’t handle CS. This class pushed me past my limit. Before taking this class I always felt that I naturally had a poor work ethic and a lack of focus and discipline on my assignments. This class showed me that my potential for endurance can only be known by pushing myself as hard as I can. There were points in this class where I would have to pull 14-hour days for weeks straight. I would get up at 7AM, start coding, and not stop until 12AM when I would go back to bed (I would take breaks to eat which probably removed ~4-5 hours of work time). This was the hardest I have ever worked on something in my life. While this semi-deteriorated a lot of relationships in my life as well as my physical health a bit, it showed me that I am capable of endurance greater than I had known before. With enough hard work and effort, I was able to finish near the top of my class and earned an A-. Because of this experience I now have a better idea of what it takes to focus and endure suffering and want to take this understanding to leadership roles in my future.\n",
            "To summarize, three of the leadership traits Steve Jobs embodied that I want to embody as well were Decisiveness, Tact, and Endurance. Steve Jobs could make decisions on a whim, strategize to put himself in positions for success, and could focus and endure for great amounts of time. While Steve Jobs was not a great person, I hope that with enough effort and leadership experience, I can embody these traits as well.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ebDwTsnCLFn"
      },
      "source": [
        "## TFIDF needs to be outside features bec. it needs to be fit on all documents, not each one separately\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, max_df=0.75)\n",
        "tfidf.fit(training_set['fixedRawText'])\n",
        "training_set['tfidf'] = tfidf.transform(training_set['fixedRawText'])"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yROvIOdDTq5-",
        "outputId": "8be588ec-33f3-4120-c6bd-c4744098472c"
      },
      "source": [
        "feature_array = np.array(tfidf.get_feature_names())\n",
        "tfidf_sorting = np.argsort(training_set['tfidf'][0].toarray()).flatten()[::-1]\n",
        "top_n = feature_array[tfidf_sorting][:10]\n",
        "top_n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['minivan', 'particular', 'tool', 'row', 'follow', 'suppose',\n",
              "       'vehicles', 'interesting', 'cannot', 'indeed'], dtype='<U17')"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "bWccc5Y0MBdV",
        "outputId": "eb8acf20-4edf-49e2-8943-1cb3e94c01b5"
      },
      "source": [
        "training_set['features'] = training_set.apply(lambda x: extractFeaturesDoc(x['tokenizedText'], x['tfidf']), axis=1)\n",
        "training_set.head()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>subject</th>\n",
              "      <th>htmlText</th>\n",
              "      <th>rawText</th>\n",
              "      <th>fixedRawText</th>\n",
              "      <th>tokenizedText</th>\n",
              "      <th>tfidf</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8842</td>\n",
              "      <td>A</td>\n",
              "      <td>\\n\\n\\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML...</td>\n",
              "      <td>While I haven’t had a ton of experiences t...</td>\n",
              "      <td>While I haven’t had a ton of experiences to sh...</td>\n",
              "      <td>[[[while, i, haven, ’, t, had, a, ton, of, exp...</td>\n",
              "      <td>(0, 4477)\\t0.020807824617396976\\n  (0, 4475)...</td>\n",
              "      <td>{'len': 5, 'tfidf':   (0, 4477)\t0.020807824617...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3647</td>\n",
              "      <td>B</td>\n",
              "      <td>\\n\\n\\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML...</td>\n",
              "      <td>Although somewhat rare in California, Subaru O...</td>\n",
              "      <td>Although somewhat rare in California, Subaru O...</td>\n",
              "      <td>[[[although, somewhat, rare, in, california, ,...</td>\n",
              "      <td>(0, 4477)\\t0.020807824617396976\\n  (0, 4475)...</td>\n",
              "      <td>{'len': 6, 'tfidf':   (0, 4477)\t0.020807824617...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2605</td>\n",
              "      <td>A</td>\n",
              "      <td>\\n\\n\\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML...</td>\n",
              "      <td>My favorite person is my high school headmaste...</td>\n",
              "      <td>My favorite person is my high school headmaste...</td>\n",
              "      <td>[[[my, favorite, person, is, my, high, school,...</td>\n",
              "      <td>(0, 4477)\\t0.020807824617396976\\n  (0, 4475)...</td>\n",
              "      <td>{'len': 7, 'tfidf':   (0, 4477)\t0.020807824617...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2592</td>\n",
              "      <td>A</td>\n",
              "      <td>\\n\\n\\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML...</td>\n",
              "      <td>One of my favorite people is Satoshi Nakamoto....</td>\n",
              "      <td>One of my favorite people is Satoshi Nakamoto....</td>\n",
              "      <td>[[[one, of, my, favorite, people, is, satoshi,...</td>\n",
              "      <td>(0, 4477)\\t0.020807824617396976\\n  (0, 4475)...</td>\n",
              "      <td>{'len': 6, 'tfidf':   (0, 4477)\t0.020807824617...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6388</td>\n",
              "      <td>B</td>\n",
              "      <td>\\n\\n\\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML...</td>\n",
              "      <td>Old Betsy was a reliable Green Honda Accord th...</td>\n",
              "      <td>Old Betsy was a reliable Green Honda Accord th...</td>\n",
              "      <td>[[[old, betsy, was, a, reliable, green, honda,...</td>\n",
              "      <td>(0, 4477)\\t0.020807824617396976\\n  (0, 4475)...</td>\n",
              "      <td>{'len': 6, 'tfidf':   (0, 4477)\t0.020807824617...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  author  ...                                           features\n",
              "0   8842  ...  {'len': 5, 'tfidf':   (0, 4477)\t0.020807824617...\n",
              "1   3647  ...  {'len': 6, 'tfidf':   (0, 4477)\t0.020807824617...\n",
              "2   2605  ...  {'len': 7, 'tfidf':   (0, 4477)\t0.020807824617...\n",
              "3   2592  ...  {'len': 6, 'tfidf':   (0, 4477)\t0.020807824617...\n",
              "4   6388  ...  {'len': 6, 'tfidf':   (0, 4477)\t0.020807824617...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "EvMdXe2fFIS9",
        "outputId": "74a7ce7d-d8d8-4e61-8d03-dee6c57d0b93"
      },
      "source": [
        "featureset_train = list(zip(training_set['features'],training_set['subject']))\n",
        "naiveBayes = nltk.classify.NaiveBayesClassifier.train(featureset_train)\n",
        "# decisionTree = nltk.classify.DecisionTreeClassifier()"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-142-39a77f5e7289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeatureset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnaiveBayes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# decisionTree = nltk.classify.DecisionTreeClassifier()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/classify/naivebayes.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Increment freq(fval|label, fname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                 \u001b[0mfeature_freqdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfval\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m                 \u001b[0;31m# Record that fname can take the value fval.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mfeature_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PmIEK9iH9Wd"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = cross_val_score(naiveBayes, X_train, y_train, cv=10, scoring=\"accuracy\")\n",
        "print(cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aI_0IU4JidD"
      },
      "source": [
        "num_folds = 10\n",
        "subset = len(training_set)/num_folds\n",
        "for i in range(num_folds):\n",
        "    test_fold = training_set[i*subset:(i+1)*subset]\n",
        "    train_fold = training_set[:i*subset] + training[(i+1)*subset:]\n",
        "    X_train = "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}