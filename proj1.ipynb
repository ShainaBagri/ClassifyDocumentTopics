{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proj1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2Bm7u_69jmQm",
        "lnOo5F3wjwUE",
        "TX0VJfz-jxKl"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShainaBagri/ClassifyDocumentTopics/blob/main/proj1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY2saR8n6wBo"
      },
      "source": [
        "# Project 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu-zBj8yirhF",
        "outputId": "121672ce-2ac0-4a01-cda1-4b252299c08d"
      },
      "source": [
        "!wget 'http://users.csc.calpoly.edu/~foaad/proj1F21_files.zip'\n",
        "!unzip 'proj1F21_files.zip'"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-22 21:53:23--  http://users.csc.calpoly.edu/~foaad/proj1F21_files.zip\n",
            "Resolving users.csc.calpoly.edu (users.csc.calpoly.edu)... 129.65.128.20\n",
            "Connecting to users.csc.calpoly.edu (users.csc.calpoly.edu)|129.65.128.20|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 129006 (126K) [application/zip]\n",
            "Saving to: ‘proj1F21_files.zip.2’\n",
            "\n",
            "proj1F21_files.zip. 100%[===================>] 125.98K   494KB/s    in 0.3s    \n",
            "\n",
            "2021-10-22 21:53:24 (494 KB/s) - ‘proj1F21_files.zip.2’ saved [129006/129006]\n",
            "\n",
            "Archive:  proj1F21_files.zip\n",
            "replace proj1F21_files/proj1F21_1412_A.html? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: proj1F21_files/proj1F21_1412_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_1412_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_1422_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_1422_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_1483_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_1483_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_1794_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_1794_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_1901_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_1901_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2404_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2404_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2422_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2422_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2509_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2509_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2592_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2592_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2605_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2605_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_2925_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_2925_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3061_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3061_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3363_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3363_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3453_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3453_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3490_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3490_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3509_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3509_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3550_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3550_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3618_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3618_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3647_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3647_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3928_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3928_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_3942_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_3942_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_4001_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_4001_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_4079_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_4079_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6218_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6218_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6388_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6388_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6533_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6533_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6585_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6585_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6728_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6728_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_6737_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_6737_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_8630_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_8630_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_8842_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_8842_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_8980_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_8980_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_9348_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_9348_B.html  \n",
            "  inflating: proj1F21_files/proj1F21_9578_A.html  \n",
            "  inflating: proj1F21_files/proj1F21_9578_B.html  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD5hswpu09YW",
        "outputId": "81a229ea-40af-438e-dee5-ec3032008318"
      },
      "source": [
        "!pip install html2text\n",
        "!pip install syllables"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: html2text in /usr/local/lib/python3.7/dist-packages (2020.1.16)\n",
            "Requirement already satisfied: syllables in /usr/local/lib/python3.7/dist-packages (1.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsfKLCZA28NW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a0a06a5-9213-49e7-fceb-b978bffe5147"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.metrics.scores import precision, recall, f_measure, accuracy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import html2text\n",
        "import collections\n",
        "import syllables\n",
        "import nltk.corpus\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "random.seed(123)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD0DHaRA6zyk"
      },
      "source": [
        "## Common Data and Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96o-B4oAlKhp"
      },
      "source": [
        "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "dir = './proj1F21_files/'"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HkMttbDh718"
      },
      "source": [
        "def getDocumentData(dir):\n",
        "  docs = []\n",
        "  for document in os.listdir(dir):\n",
        "    dict = {}\n",
        "    docName = document.split(\"_\")\n",
        "    dict['author'] = docName[1]\n",
        "    dict['subject'] = docName[2][0]\n",
        "    with open(dir + document) as f:\n",
        "      dict['htmlText'] = f.read()\n",
        "      dict['rawText'] = html2text.html2text(dict['htmlText'])\n",
        "      dict['fixedRawText'] = fixRaw(dict['rawText'])\n",
        "      dict['tokenizedText'] = tokDoc(dict['fixedRawText']) \n",
        "    docs.append(dict)\n",
        "  return docs\n",
        "\n",
        "def getParagraphData(dir):\n",
        "  docs = []\n",
        "  for document in os.listdir(dir):\n",
        "    docName = document.split(\"_\")\n",
        "    with open(dir + document) as f:\n",
        "      htmlText = f.read()\n",
        "      rawText = html2text.html2text(htmlText)\n",
        "      text = fixRaw(rawText).split('\\n')\n",
        "      for par in text:\n",
        "        if par!=[]:\n",
        "          dict = {}\n",
        "          dict['author'] = docName[1]\n",
        "          dict['subject'] = docName[2][0]\n",
        "          dict['rawText'] = par\n",
        "          dict['tokenizedText'] = tokPar(dict['rawText']) \n",
        "          if dict['tokenizedText']!=[]:\n",
        "            docs.append(dict)\n",
        "  return docs\n",
        "\n",
        "def getSentenceData(dir):\n",
        "  docs = []\n",
        "  for document in os.listdir(dir):\n",
        "    docName = document.split(\"_\")\n",
        "    with open(dir + document) as f:\n",
        "      htmlText = f.read()\n",
        "      rawText = html2text.html2text(htmlText)\n",
        "      text = fixRaw(rawText).split('\\n')\n",
        "      for par in text:\n",
        "        sents = sent_tokenizer.tokenize(par)\n",
        "        for sent in sents:\n",
        "          dict = {}\n",
        "          dict['author'] = docName[1]\n",
        "          dict['subject'] = docName[2][0]\n",
        "          dict['rawText'] = sent\n",
        "          dict['tokenizedText'] = tokSent(dict['rawText']) \n",
        "          docs.append(dict)\n",
        "  return docs\n",
        "\n",
        "# split into training and test sets\n",
        "# takes in dictionary\n",
        "# returns pandas dataframes\n",
        "def splitTrainTest(data):\n",
        "  random.shuffle(data)\n",
        "  split = int(len(data) *0.8)\n",
        "  test_set = pd.DataFrame(data[split:])\n",
        "  training_set = pd.DataFrame(data[:split])\n",
        "  return training_set, test_set"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS1V5EDI5ZXi"
      },
      "source": [
        "def fixRaw(text):\n",
        "  newText = \"\"\n",
        "  for p in re.split('\\n\\n+', text):\n",
        "    newText = newText + p.replace('\\n', ' ').strip() + '\\n'\n",
        "  return newText\n",
        "\n",
        "def tokSent(text):\n",
        "  return [word.lower() for word in nltk.word_tokenize(text)]\n",
        "\n",
        "def tokPar(text):\n",
        "  sents = sent_tokenizer.tokenize(text)\n",
        "  goodSents = []\n",
        "  for sent in sents:\n",
        "    goodSents.append(tokSent(sent))\n",
        "  return goodSents\n",
        "\n",
        "def tokDoc(text):\n",
        "  goodParas = []\n",
        "  for para in text.split('\\n'):\n",
        "    goodParas.append(tokPar(para))\n",
        "  return goodParas"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzy1w6YowEnl"
      },
      "source": [
        "def getRelatedWords(subject, depth):\n",
        "    \"\"\"\n",
        "    Returns a list of words related to the given subject. Uses wordnet and explores\n",
        "    hyponyms up to given depth.\n",
        "\n",
        "    Reccomended depth of 4 for vehicle and 1 for person\n",
        "    \"\"\"\n",
        "    words = set({})\n",
        "    for c in wn.synsets(subject, pos=wn.NOUN):\n",
        "        words |= recGetRelated(c, depth)\n",
        " \n",
        "    return words\n",
        "    \n",
        "\n",
        "def recGetRelated(sub, depth):\n",
        "    \"\"\"\n",
        "    Recursively gets the related words up to given depth\n",
        "    \"\"\"\n",
        "    if depth == 0:\n",
        "        return set({})\n",
        "    \n",
        "    concepts = [sub]\n",
        "    concepts += sub.hyponyms()\n",
        "    \n",
        "    words = set({})\n",
        "    for c in concepts:\n",
        "        words |= recGetRelated(c, depth - 1) # recursive call\n",
        "        for l in c.lemmas():\n",
        "            name = l.name()\n",
        "            if '_' not in name:\n",
        "                # removes multi word lemmas\n",
        "                words.add(name)\n",
        "    \n",
        "    return words\n",
        "\n",
        "vehicleCat = getRelatedWords(\"vehicle\", 4)\n",
        "personCat = getRelatedWords(\"person\", 1) | {\"born\"}"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aI_0IU4JidD"
      },
      "source": [
        "# for development purposes\n",
        "def crossValTestSubject(training_set):\n",
        "  num_folds = 10\n",
        "  subset = int(len(training_set)/num_folds)\n",
        "  nbAccuracy = []\n",
        "  nbPrecision = []\n",
        "  nbRecall = []\n",
        "  nbF1 = []\n",
        "  dtAccuracy = []\n",
        "  dtPrecision = []\n",
        "  dtRecall = []\n",
        "  dtF1 = []\n",
        "  for i in range(num_folds):\n",
        "      test_fold = training_set.loc[i*subset:(i+1)*subset]\n",
        "      train_fold = pd.concat([training_set.loc[:i*subset], training_set.loc[(i+1)*subset:]])\n",
        "      featureset_train = list(zip(train_fold['features'],train_fold['subject']))\n",
        "      featureset_test = list(zip(test_fold['features'],test_fold['subject']))\n",
        "      naiveBayes = nltk.classify.NaiveBayesClassifier.train(featureset_train)\n",
        "      decisionTree = nltk.classify.DecisionTreeClassifier.train(featureset_train)\n",
        "\n",
        "      expected = collections.defaultdict(set)\n",
        "      nbPred = collections.defaultdict(set)\n",
        "      dtPred = collections.defaultdict(set)\n",
        "\n",
        "      for j, (feats, label) in enumerate(featureset_test):\n",
        "        expected[label].add(j)\n",
        "        observed = naiveBayes.classify(feats)\n",
        "        nbPred[observed].add(j)\n",
        "        observed2 = decisionTree.classify(feats)\n",
        "        dtPred[observed2].add(j)\n",
        "      \n",
        "      nbAccuracy.append(nltk.classify.accuracy(naiveBayes, featureset_test))\n",
        "      dtAccuracy.append(nltk.classify.accuracy(decisionTree, featureset_test))\n",
        "      for k in expected:\n",
        "        nbPrecision.append(precision(expected[k], nbPred[k]))\n",
        "        nbRecall.append(recall(expected[k], nbPred[k]))\n",
        "        nbF1.append(f_measure(expected[k], nbPred[k]))\n",
        "\n",
        "        dtPrecision.append(precision(expected[k], dtPred[k]))\n",
        "        dtRecall.append(recall(expected[k], dtPred[k]))\n",
        "        dtF1.append(f_measure(expected[k], dtPred[k]))\n",
        "\n",
        "  nbAccuracy = [x for x in nbAccuracy if x]\n",
        "  nbPrecision = [x for x in nbPrecision if x]\n",
        "  nbRecall = [x for x in nbRecall if x]\n",
        "  nbF1 = [x for x in nbF1 if x]\n",
        "  dtAccuracy = [x for x in dtAccuracy if x]\n",
        "  dtPrecision = [x for x in dtPrecision if x]\n",
        "  dtRecall = [x for x in dtRecall if x]\n",
        "  dtF1 = [x for x in dtF1 if x]\n",
        "\n",
        "  print(\"CROSS VAL METRICS:\")\n",
        "  print(\"NB Accuracy:\", sum(nbAccuracy)/len(nbAccuracy))\n",
        "  print(\"NB Precision:\", sum(nbPrecision)/len(nbPrecision))\n",
        "  print(\"NB Recall:\", sum(nbRecall)/len(nbRecall))\n",
        "  print(\"NB F1:\", sum(nbF1)/len(nbF1))\n",
        "  print(\"DT Accuracy:\", sum(dtAccuracy)/len(dtAccuracy))\n",
        "  print(\"DT Precision:\", sum(dtPrecision)/len(dtPrecision))\n",
        "  print(\"DT Recall:\", sum(dtRecall)/len(dtRecall))\n",
        "  print(\"DT F1:\", sum(dtF1)/len(dtF1))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OJe0d8N3Kgf"
      },
      "source": [
        "# actual metrics\n",
        "def actualMetricsSubject(training_set, test_set):\n",
        "    nbPrecision = []\n",
        "    nbRecall = []\n",
        "    nbF1 = []\n",
        "    # dtPrecision = []\n",
        "    # dtRecall = []\n",
        "    # dtF1 = []\n",
        "\n",
        "    featureset_train = list(zip(training_set['features'],training_set['subject']))\n",
        "    featureset_test = list(zip(test_set['features'],test_set['subject']))\n",
        "    naiveBayes = nltk.classify.NaiveBayesClassifier.train(featureset_train)\n",
        "    # decisionTree = nltk.classify.DecisionTreeClassifier.train(featureset_train)\n",
        "\n",
        "    expected = collections.defaultdict(set)\n",
        "    nbPred = collections.defaultdict(set)\n",
        "    # dtPred = collections.defaultdict(set)\n",
        "\n",
        "    for j, (feats, label) in enumerate(featureset_test):\n",
        "      expected[label].add(j)\n",
        "      observed = naiveBayes.classify(feats)\n",
        "      nbPred[observed].add(j)\n",
        "      # observed2 = decisionTree.classify(feats)\n",
        "      # dtPred[observed2].add(j)\n",
        "      \n",
        "      nbAccuracy = nltk.classify.accuracy(naiveBayes, featureset_test)\n",
        "      # dtAccuracy = nltk.classify.accuracy(decisionTree, featureset_test)\n",
        "      for k in expected:\n",
        "        nbPrecision.append(precision(expected[k], nbPred[k]))\n",
        "        nbRecall.append(recall(expected[k], nbPred[k]))\n",
        "        nbF1.append(f_measure(expected[k], nbPred[k]))\n",
        "\n",
        "        # dtPrecision.append(precision(expected[k], dtPred[k]))\n",
        "        # dtRecall.append(recall(expected[k], dtPred[k]))\n",
        "        # dtF1.append(f_measure(expected[k], dtPred[k]))\n",
        "\n",
        "    nbPrecision = [x for x in nbPrecision if x]\n",
        "    nbRecall = [x for x in nbRecall if x]\n",
        "    nbF1 = [x for x in nbF1 if x]\n",
        "    # dtPrecision = [x for x in dtPrecision if x]\n",
        "    # dtRecall = [x for x in dtRecall if x]\n",
        "    # dtF1 = [x for x in dtF1 if x]\n",
        "\n",
        "    print(\"PREDICTIONS:\")\n",
        "    print(nbPred)\n",
        "    print()\n",
        "    print(\"ACTUAL METRICS:\")\n",
        "    print(\"NB Accuracy:\", nbAccuracy)\n",
        "    print(\"NB Precision:\", sum(nbPrecision)/len(nbPrecision))\n",
        "    print(\"NB Recall:\", sum(nbRecall)/len(nbRecall))\n",
        "    print(\"NB F1:\", sum(nbF1)/len(nbF1))\n",
        "    # print()\n",
        "    # print(\"DT Accuracy:\", dtAccuracy)\n",
        "    # print(\"DT Precision:\", sum(dtPrecision)/len(dtPrecision))\n",
        "    # print(\"DT Recall:\", sum(dtRecall)/len(dtRecall))\n",
        "    # print(\"DT F1:\", sum(dtF1)/len(dtF1))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfCpNybhEs6m"
      },
      "source": [
        "# for development purposes\n",
        "def crossValTestAuthor(training_set):\n",
        "  num_folds = 10\n",
        "  subset = int(len(training_set)/num_folds)\n",
        "  nbAccuracy = []\n",
        "  nbPrecision = []\n",
        "  nbRecall = []\n",
        "  nbF1 = []\n",
        "  dtAccuracy = []\n",
        "  dtPrecision = []\n",
        "  dtRecall = []\n",
        "  dtF1 = []\n",
        "  for i in range(num_folds):\n",
        "      test_fold = training_set.loc[i*subset:(i+1)*subset]\n",
        "      train_fold = pd.concat([training_set.loc[:i*subset], training_set.loc[(i+1)*subset:]])\n",
        "      featureset_train = list(zip(train_fold['features'],train_fold['author']))\n",
        "      featureset_test = list(zip(test_fold['features'],test_fold['author']))\n",
        "      naiveBayes = nltk.classify.NaiveBayesClassifier.train(featureset_train)\n",
        "      decisionTree = nltk.classify.DecisionTreeClassifier.train(featureset_train)\n",
        "\n",
        "      expected = collections.defaultdict(set)\n",
        "      nbPred = collections.defaultdict(set)\n",
        "      dtPred = collections.defaultdict(set)\n",
        "\n",
        "      for j, (feats, label) in enumerate(featureset_test):\n",
        "        expected[label].add(j)\n",
        "        observed = naiveBayes.classify(feats)\n",
        "        nbPred[observed].add(j)\n",
        "        observed2 = decisionTree.classify(feats)\n",
        "        dtPred[observed2].add(j)\n",
        "      \n",
        "      nbAccuracy.append(nltk.classify.accuracy(naiveBayes, featureset_test))\n",
        "      dtAccuracy.append(nltk.classify.accuracy(decisionTree, featureset_test))\n",
        "      for k in expected:\n",
        "        nbPrecision.append(precision(expected[k], nbPred[k]))\n",
        "        nbRecall.append(recall(expected[k], nbPred[k]))\n",
        "        nbF1.append(f_measure(expected[k], nbPred[k]))\n",
        "\n",
        "        dtPrecision.append(precision(expected[k], dtPred[k]))\n",
        "        dtRecall.append(recall(expected[k], dtPred[k]))\n",
        "        dtF1.append(f_measure(expected[k], dtPred[k]))\n",
        "\n",
        "  nbAccuracy = [x for x in nbAccuracy if x]\n",
        "  nbPrecision = [x for x in nbPrecision if x]\n",
        "  nbRecall = [x for x in nbRecall if x]\n",
        "  nbF1 = [x for x in nbF1 if x]\n",
        "  dtAccuracy = [x for x in dtAccuracy if x]\n",
        "  dtPrecision = [x for x in dtPrecision if x]\n",
        "  dtRecall = [x for x in dtRecall if x]\n",
        "  dtF1 = [x for x in dtF1 if x]\n",
        "\n",
        "  print(\"CROSS VAL METRICS:\")\n",
        "  print(\"NB Accuracy:\", sum(nbAccuracy)/len(nbAccuracy))\n",
        "  print(\"NB Precision:\", sum(nbPrecision)/len(nbPrecision))\n",
        "  print(\"NB Recall:\", sum(nbRecall)/len(nbRecall))\n",
        "  print(\"NB F1:\", sum(nbF1)/len(nbF1))\n",
        "  print(\"DT Accuracy:\", sum(dtAccuracy)/len(dtAccuracy))\n",
        "  print(\"DT Precision:\", sum(dtPrecision)/len(dtPrecision))\n",
        "  print(\"DT Recall:\", sum(dtRecall)/len(dtRecall))\n",
        "  print(\"DT F1:\", sum(dtF1)/len(dtF1))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1tfkVYiEySN"
      },
      "source": [
        "# actual metrics\n",
        "def actualMetricsAuthor(training_set, test_set):\n",
        "    nbPrecision = []\n",
        "    nbRecall = []\n",
        "    nbF1 = []\n",
        "    # dtPrecision = []\n",
        "    # dtRecall = []\n",
        "    # dtF1 = []\n",
        "\n",
        "    featureset_train = list(zip(training_set['features'],training_set['author']))\n",
        "    featureset_test = list(zip(test_set['features'],test_set['author']))\n",
        "    naiveBayes = nltk.classify.NaiveBayesClassifier.train(featureset_train)\n",
        "    decisionTree = nltk.classify.DecisionTreeClassifier.train(featureset_train)\n",
        "\n",
        "    expected = collections.defaultdict(set)\n",
        "    nbPred = collections.defaultdict(set)\n",
        "    dtPred = collections.defaultdict(set)\n",
        "\n",
        "    for j, (feats, label) in enumerate(featureset_test):\n",
        "      expected[label].add(j)\n",
        "      observed = naiveBayes.classify(feats)\n",
        "      nbPred[observed].add(j)\n",
        "      observed2 = decisionTree.classify(feats)\n",
        "      dtPred[observed2].add(j)\n",
        "      \n",
        "      nbAccuracy = nltk.classify.accuracy(naiveBayes, featureset_test)\n",
        "      dtAccuracy = nltk.classify.accuracy(decisionTree, featureset_test)\n",
        "      for k in expected:\n",
        "        nbPrecision.append(precision(expected[k], nbPred[k]))\n",
        "        nbRecall.append(recall(expected[k], nbPred[k]))\n",
        "        nbF1.append(f_measure(expected[k], nbPred[k]))\n",
        "\n",
        "        dtPrecision.append(precision(expected[k], dtPred[k]))\n",
        "        dtRecall.append(recall(expected[k], dtPred[k]))\n",
        "        dtF1.append(f_measure(expected[k], dtPred[k]))\n",
        "\n",
        "    nbPrecision = [x for x in nbPrecision if x]\n",
        "    nbRecall = [x for x in nbRecall if x]\n",
        "    nbF1 = [x for x in nbF1 if x]\n",
        "    dtPrecision = [x for x in dtPrecision if x]\n",
        "    dtRecall = [x for x in dtRecall if x]\n",
        "    dtF1 = [x for x in dtF1 if x]\n",
        "\n",
        "    print(\"PREDICTIONS:\")\n",
        "    print(nbPred)\n",
        "    print()\n",
        "    print(\"ACTUAL METRICS:\")\n",
        "    print(\"NB Accuracy:\", nbAccuracy)\n",
        "    print(\"NB Precision:\", sum(nbPrecision)/len(nbPrecision))\n",
        "    print(\"NB Recall:\", sum(nbRecall)/len(nbRecall))\n",
        "    print(\"NB F1:\", sum(nbF1)/len(nbF1))\n",
        "    print()\n",
        "    print(\"DT Accuracy:\", dtAccuracy)\n",
        "    print(\"DT Precision:\", sum(dtPrecision)/len(dtPrecision))\n",
        "    print(\"DT Recall:\", sum(dtRecall)/len(dtRecall))\n",
        "    print(\"DT F1:\", sum(dtF1)/len(dtF1))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bm7u_69jmQm"
      },
      "source": [
        "## Identify Subject by Document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHL82cu4y6zk"
      },
      "source": [
        "def extractFeaturesDoc(tokText, vehicleCat, personCat):\n",
        "  \"\"\"\n",
        "  Extracts features from a document and returns them as a dictionary where\n",
        "  vehicleCat and personCat are sets of words related to the subjects\n",
        "  \"\"\"\n",
        " \n",
        "  features = {}\n",
        "\n",
        "  # Wordnet words related to person or vehicle\n",
        "  vehicleCount = sum([sum([len([w for w in s if w in vehicleCat]) for s in p]) for p in tokText])\n",
        "  personCount = sum([sum([len([w for w in s if w in personCat]) for s in p]) for p in tokText])\n",
        "  lenDoc = sum([sum([len(s) for s in p]) for p in tokText])\n",
        "\n",
        "  relatedThresh = 0.005\n",
        "  features['vehicleRelatedWC'] = 1 if vehicleCount / lenDoc > relatedThresh else 0\n",
        "  features['personRelatedWC'] = 1 if personCount / lenDoc > relatedThresh else 0\n",
        "\n",
        "  return features"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGT5vFnnlw5F",
        "outputId": "bcb43cf3-770a-4782-e21c-06ac3967c304"
      },
      "source": [
        "data = getDocumentData(dir)\n",
        "training_set, test_set = splitTrainTest(data)\n",
        "training_set['features'] = training_set.apply(lambda x: extractFeaturesDoc(x['tokenizedText'], vehicleCat, personCat), axis=1)\n",
        "test_set['features'] = test_set.apply(lambda x: extractFeaturesDoc(x['tokenizedText'], vehicleCat, personCat), axis=1)\n",
        "crossValTestSubject(training_set)\n",
        "print()\n",
        "actualMetricsSubject(training_set, test_set)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CROSS VAL METRICS:\n",
            "NB Accuracy: 0.9666666666666666\n",
            "NB Precision: 0.9775\n",
            "NB Recall: 0.9583333333333334\n",
            "NB F1: 0.9606349206349207\n",
            "DT Accuracy: 0.9666666666666666\n",
            "DT Precision: 0.9775\n",
            "DT Recall: 0.9583333333333334\n",
            "DT F1: 0.9606349206349207\n",
            "\n",
            "PREDICTIONS:\n",
            "defaultdict(<class 'set'>, {'A': {0, 1, 3, 4, 6, 8, 9, 10, 12}, 'B': {2, 5, 7, 11, 13}})\n",
            "\n",
            "ACTUAL METRICS:\n",
            "NB Accuracy: 1.0\n",
            "NB Precision: 1.0\n",
            "NB Recall: 1.0\n",
            "NB F1: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnOo5F3wjwUE"
      },
      "source": [
        "## Identify Subject by Paragraph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRERy67pzI5Z"
      },
      "source": [
        "def extractFeaturesPar(tokText, vehicleCat, personCat):\n",
        "  \"\"\"\n",
        "  Extracts features from a document and returns them as a dictionary where\n",
        "  vehicleCat and personCat are sets of words related to the subjects\n",
        "  \"\"\"\n",
        " \n",
        "  features = {}\n",
        "\n",
        "  # Wordnet words related to person or vehicle\n",
        "  vehicleCount = sum([len([w for w in s if w in vehicleCat]) for s in tokText])\n",
        "  personCount = sum([len([w for w in s if w in personCat]) for s in tokText])\n",
        "  lenDoc = sum([len(s) for s in tokText])\n",
        "\n",
        "  relatedThresh = 0.005\n",
        "  features['vehicleRelatedWC'] = 1 if vehicleCount / lenDoc > relatedThresh else 0\n",
        "  features['personRelatedWC'] = 1 if personCount / lenDoc > relatedThresh else 0\n",
        "\n",
        "  return features"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlImSc4OwBc0",
        "outputId": "aca79b0a-afbc-436a-88d9-ad2b4e1f6a49"
      },
      "source": [
        "data = getParagraphData(dir)\n",
        "training_set, test_set = splitTrainTest(data)\n",
        "training_set['features'] = training_set.apply(lambda x: extractFeaturesPar(x['tokenizedText'], vehicleCat, personCat), axis=1)\n",
        "test_set['features'] = test_set.apply(lambda x: extractFeaturesPar(x['tokenizedText'], vehicleCat, personCat), axis=1)\n",
        "crossValTestSubject(training_set)\n",
        "print()\n",
        "actualMetricsSubject(training_set, test_set)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CROSS VAL METRICS:\n",
            "NB Accuracy: 0.9407407407407407\n",
            "NB Precision: 0.9470373131770191\n",
            "NB Recall: 0.9404308885558887\n",
            "NB F1: 0.9392867656390796\n",
            "DT Accuracy: 0.9407407407407407\n",
            "DT Precision: 0.9470373131770191\n",
            "DT Recall: 0.9404308885558887\n",
            "DT F1: 0.9392867656390796\n",
            "\n",
            "PREDICTIONS:\n",
            "defaultdict(<class 'set'>, {'A': {0, 1, 3, 4, 5, 6, 7, 10, 11, 12, 15, 20, 21, 24, 25, 27, 28, 30, 35, 38, 39, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 62, 66, 67}, 'B': {2, 8, 9, 13, 14, 16, 17, 18, 19, 22, 23, 26, 29, 31, 32, 33, 34, 36, 37, 40, 41, 43, 46, 48, 55, 58, 63, 64, 65}})\n",
            "\n",
            "ACTUAL METRICS:\n",
            "NB Accuracy: 0.9117647058823529\n",
            "NB Precision: 0.8733169519145537\n",
            "NB Recall: 0.864711753648792\n",
            "NB F1: 0.8655611305147388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX0VJfz-jxKl"
      },
      "source": [
        "## Identify Subject by Sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAa3WTzV0EXw"
      },
      "source": [
        "def extractFeaturesSent(tokText, vehicleCat, personCat):\n",
        "  \"\"\"\n",
        "  Extracts features from a document and returns them as a dictionary where\n",
        "  vehicleCat and personCat are sets of words related to the subjects\n",
        "  \"\"\"\n",
        " \n",
        "  features = {}\n",
        "\n",
        "  # Wordnet words related to person or vehicle\n",
        "  vehicleCount = len([w for w in tokText if w in vehicleCat])\n",
        "  personCount = len([w for w in tokText if w in personCat])\n",
        "  lenDoc = len(tokText)\n",
        "\n",
        "  features['vehicleRelatedWC'] = 1 if vehicleCount >= 1 else 0\n",
        "  features['personRelatedWC'] = 1 if personCount >= 1 else 0\n",
        "  # features['containsNum'] = 1 if len([w for w in tokText if w.isnumeric()]) > 1 else 0\n",
        "\n",
        "  return features"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd-N12cj0fVH",
        "outputId": "a9377b63-3ae7-4a8d-e9e9-94d85b9b8f92"
      },
      "source": [
        "data = getSentenceData(dir)\n",
        "training_set, test_set = splitTrainTest(data)\n",
        "training_set['features'] = training_set.apply(lambda x: extractFeaturesSent(x['tokenizedText'], vehicleCat, personCat), axis=1)\n",
        "crossValTestSubject(training_set)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CROSS VAL METRICS:\n",
            "NB Accuracy: 0.7280201342281879\n",
            "NB Precision: 0.8094615601683948\n",
            "NB Recall: 0.7278545495580319\n",
            "NB F1: 0.7067505363577231\n",
            "DT Accuracy: 0.7280201342281879\n",
            "DT Precision: 0.8094615601683948\n",
            "DT Recall: 0.7278545495580319\n",
            "DT F1: 0.7067505363577231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0qZlpJkjxWy"
      },
      "source": [
        "## Identify Author by Document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfS8fxMj8vym"
      },
      "source": [
        "stopWords = stopwords.words('english')\n",
        "\n",
        "def getTopWordsDoc(features, n, doc):\n",
        "    \"\"\"\n",
        "    Gets the n most common words and adds it to the feature list.\n",
        "    Does not include non alpha words or stopwords\n",
        "    \"\"\"\n",
        "\n",
        "    # Filter stopwords and get frequency\n",
        "    words = []\n",
        "    for p in doc:\n",
        "        for s in p:\n",
        "            for w in s:\n",
        "                if w.isalpha() and w not in stopWords:\n",
        "                    words.append(w)\n",
        "\n",
        "    freq = [w[0] for w in FreqDist(words).most_common(n)]\n",
        "\n",
        "    for i in range(n):\n",
        "        features[\"topWord\" + str(i)] = freq[i]\n",
        "\n",
        "def extractFeaturesAuthDoc(tokText):\n",
        "  \"\"\"\n",
        "  Extracts features from a document and returns them as a dictionary where\n",
        "  vehicleCat and personCat are sets of words related to the subjects\n",
        "  \"\"\"\n",
        " \n",
        "  features = {}\n",
        "\n",
        "  avgParLen = sum([len(p) for p in tokText])/len(tokText)\n",
        "  avgSenLen = sum([sum([len(s) for s in p]) for p in tokText])/sum([len(p) for p in tokText])\n",
        "  numCommas = sum([sum([len([c for c in s if c==\",\"]) for s in p]) for p in tokText])\n",
        "\n",
        "  features['avgParLen'] = avgParLen\n",
        "  features['avgSenLen'] = avgSenLen\n",
        "  # features['numCommas'] = numCommas//5\n",
        "  getTopWordsDoc(features, 3, tokText)\n",
        "\n",
        "  return features"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc6hQyET8v8-",
        "outputId": "0d6753b3-efbc-42fe-f1ea-27a05ba9ec5f"
      },
      "source": [
        "data = getDocumentData(dir)\n",
        "training_set, test_set = splitTrainTest(data)\n",
        "training_set['features'] = training_set.apply(lambda x: extractFeaturesAuthDoc(x['tokenizedText']), axis=1)\n",
        "crossValTestAuthor(training_set)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CROSS VAL METRICS:\n",
            "NB Accuracy: 0.33333333333333337\n",
            "NB Precision: 0.875\n",
            "NB Recall: 0.95\n",
            "NB F1: 0.8833333333333334\n",
            "DT Accuracy: 0.35000000000000003\n",
            "DT Precision: 0.9642857142857143\n",
            "DT Recall: 0.9523809523809523\n",
            "DT F1: 0.9396825396825397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwA7HfQZj9oA"
      },
      "source": [
        "## Identify Author by Paragraph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VrcinvFLnr3"
      },
      "source": [
        "def getTopWordsPara(features, n, doc):\n",
        "    \"\"\"\n",
        "    Gets the n most common words and adds it to the feature list.\n",
        "    Does not include non alpha words or stopwords\n",
        "    \"\"\"\n",
        "\n",
        "    # Filter stopwords and get frequency\n",
        "    words = []\n",
        "    for s in doc:\n",
        "      for w in s:\n",
        "        if w.isalpha() and w not in stopWords:\n",
        "            words.append(w)\n",
        "\n",
        "    freq = [w[0] for w in FreqDist(words).most_common(n)]\n",
        "\n",
        "    for i in range(min(n, len(freq))):\n",
        "        features[\"topWord\" + str(i)] = freq[i]\n",
        "\n",
        "syllable_dict= nltk.corpus.cmudict.dict() \n",
        "\n",
        "def get_syllables(word):\n",
        "  if word.lower() in syllable_dict.keys():\n",
        "    syl_count = 0\n",
        "    syl_list = syllable_dict[word.lower()][0]\n",
        "    for ele in syl_list:\n",
        "      if ele[-1].isdigit():\n",
        "        syl_count += 1\n",
        "    return syl_count\n",
        "  else:\n",
        "    return syllables.estimate(word) \n",
        "\n",
        "def isStopword(word):\n",
        "  if word in stopWords:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltmrzoX78xAx"
      },
      "source": [
        "def extractFeaturesAuthPar(tokText):\n",
        "  \"\"\"\n",
        "  Extracts features from a document and returns them as a dictionary where\n",
        "  vehicleCat and personCat are sets of words related to the subjects\n",
        "  \"\"\"\n",
        " \n",
        "  features = {}\n",
        "\n",
        "  avgParLen = sum([len(p) for p in tokText])/len(tokText)\n",
        "  avgSenLen = sum([sum([len(s) for s in p]) for p in tokText])/sum([len(p) for p in tokText])\n",
        "  avgSyl = sum([sum([sum([get_syllables(w) for w in s]) for s in p]) for p in tokText])/sum([sum([len(s) for s in p]) for p in tokText])\n",
        "  avgUniqueWords= sum([sum([len(set(s.split())) for s in p]) for p in tokText])/sum([sum([len(s) for s in p]) for p in tokText])\n",
        "  avgStopWords = sum([sum([sum([isStopword(w) for w in s]) for s in p]) for p in tokText])/sum([sum([len(s) for s in p]) for p in tokText])\n",
        "  \n",
        "\n",
        "\n",
        "  features['avgParLen'] = avgParLen\n",
        "  features['avgSenLen'] = avgSenLen\n",
        "  features['avgSyl'] = 1 if (avgSyl) <= 3 else 0\n",
        "  print(avgSyl)\n",
        "  # features['avgUniqueWords'] = 1 if(avgUniqueWords) >= 5 else 0\n",
        "  features['avgUniqueWords'] = round(avgUniqueWords * 10)\n",
        "  # features['avgStopWords'] = 1 if(avgStopWords) <=5 else 0\n",
        "  features['avgStopWords'] = round(avgStopWords * 10)\n",
        "  getTopWordsPara(features, 5, tokText)\n",
        "\n",
        "#ah;ldsfjas;ldjf\n",
        "\n",
        "  return features"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8anNoD0D8xGr",
        "outputId": "1b02eb60-2cb8-40fe-f59e-ac617b197860"
      },
      "source": [
        "data = getParagraphData(dir)\n",
        "training_set, test_set = splitTrainTest(data)\n",
        "training_set['features'] = training_set.apply(lambda x: extractFeaturesAuthPar(x['tokenizedText']), axis=1)\n",
        "crossValTestAuthor(training_set)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0187793427230047\n",
            "1.0616570327552985\n",
            "1.0151975683890577\n",
            "1.0485933503836318\n",
            "1.0270880361173815\n",
            "1.0436456996148908\n",
            "1.0459016393442624\n",
            "1.037079953650058\n",
            "1.0163934426229508\n",
            "1.0485981308411214\n",
            "1.0372670807453417\n",
            "1.0330827067669173\n",
            "1.0185185185185186\n",
            "1.0727272727272728\n",
            "1.0401854714064915\n",
            "1.024390243902439\n",
            "1.0261865793780687\n",
            "1.0392156862745099\n",
            "1.0357142857142858\n",
            "1.0639834881320949\n",
            "1.0260756192959584\n",
            "1.0486725663716814\n",
            "1.0635593220338984\n",
            "1.0472972972972974\n",
            "1.0528455284552845\n",
            "1.0315581854043392\n",
            "1.0282186948853616\n",
            "1.0350194552529184\n",
            "1.0\n",
            "1.044776119402985\n",
            "1.02020202020202\n",
            "1.0463576158940397\n",
            "1.0368098159509203\n",
            "1.0040899795501022\n",
            "1.0081632653061225\n",
            "1.0322061191626408\n",
            "1.0341463414634147\n",
            "1.0693877551020408\n",
            "1.0307692307692307\n",
            "1.0857142857142856\n",
            "1.051150895140665\n",
            "1.0344827586206897\n",
            "1.0387722132471728\n",
            "1.0392156862745099\n",
            "1.0443037974683544\n",
            "1.03690036900369\n",
            "1.0717948717948718\n",
            "1.0356687898089172\n",
            "1.0398406374501992\n",
            "1.0226628895184136\n",
            "1.0833333333333333\n",
            "1.048951048951049\n",
            "1.0560224089635855\n",
            "1.048411497730711\n",
            "1.0491803278688525\n",
            "1.046908315565032\n",
            "1.0446601941747573\n",
            "1.0319148936170213\n",
            "1.043343653250774\n",
            "1.0425531914893618\n",
            "1.08\n",
            "1.0574162679425838\n",
            "1.0414507772020725\n",
            "1.048\n",
            "1.0346534653465347\n",
            "1.0542168674698795\n",
            "1.0476190476190477\n",
            "1.0094117647058825\n",
            "1.0311526479750779\n",
            "1.0104712041884816\n",
            "1.0205278592375366\n",
            "1.0495356037151702\n",
            "1.042446941323346\n",
            "1.048780487804878\n",
            "1.0363636363636364\n",
            "1.0363636363636364\n",
            "1.1185983827493262\n",
            "1.010840108401084\n",
            "1.0217391304347827\n",
            "1.0223048327137547\n",
            "1.0386100386100385\n",
            "1.0215716486902928\n",
            "1.0437956204379562\n",
            "1.0380313199105144\n",
            "1.0307328605200945\n",
            "1.0275482093663912\n",
            "1.04472049689441\n",
            "1.015748031496063\n",
            "1.0315581854043392\n",
            "1.028169014084507\n",
            "1.0323886639676114\n",
            "1.0219298245614035\n",
            "1.0233463035019454\n",
            "1.0334448160535117\n",
            "1.0263852242744063\n",
            "1.0465116279069768\n",
            "1.0377867746288798\n",
            "1.0176211453744493\n",
            "1.0504731861198737\n",
            "1.0449438202247192\n",
            "1.027237354085603\n",
            "1.0390243902439025\n",
            "1.0318091451292246\n",
            "1.0278551532033426\n",
            "1.034416826003824\n",
            "1.0819672131147542\n",
            "1.0276338514680483\n",
            "1.0413793103448277\n",
            "1.0844036697247705\n",
            "1.0211360634081903\n",
            "1.0341296928327646\n",
            "1.020100502512563\n",
            "1.035928143712575\n",
            "1.0338409475465313\n",
            "1.0253807106598984\n",
            "1.017738359201774\n",
            "1.0430622009569377\n",
            "1.061611374407583\n",
            "1.04221635883905\n",
            "1.0404040404040404\n",
            "1.0212765957446808\n",
            "1.047244094488189\n",
            "1.050125313283208\n",
            "1.0238663484486874\n",
            "1.0342465753424657\n",
            "1.0337552742616034\n",
            "1.0511627906976744\n",
            "1.0291595197255574\n",
            "1.0372093023255815\n",
            "1.0551181102362204\n",
            "1.0320512820512822\n",
            "1.0210526315789474\n",
            "1.030188679245283\n",
            "1.0366666666666666\n",
            "1.0702576112412179\n",
            "1.032258064516129\n",
            "1.0627674750356633\n",
            "1.0887372013651877\n",
            "1.0309597523219813\n",
            "1.0753138075313808\n",
            "1.046242774566474\n",
            "1.0087336244541485\n",
            "1.031331592689295\n",
            "1.066420664206642\n",
            "1.0611916264090178\n",
            "1.0501392757660166\n",
            "1.0245398773006136\n",
            "1.04\n",
            "1.0279441117764472\n",
            "1.0298507462686568\n",
            "1.0182370820668694\n",
            "1.0541455160744502\n",
            "1.0318091451292246\n",
            "1.046875\n",
            "1.0587155963302752\n",
            "1.0754716981132075\n",
            "1.059850374064838\n",
            "1.0376344086021505\n",
            "1.0301075268817204\n",
            "1.043076923076923\n",
            "1.043521266073195\n",
            "1.0490463215258856\n",
            "1.0384615384615385\n",
            "1.029520295202952\n",
            "1.0316742081447965\n",
            "1.0133333333333334\n",
            "1.0837696335078535\n",
            "1.0161616161616163\n",
            "1.0327868852459017\n",
            "1.0477223427331888\n",
            "1.0763358778625953\n",
            "1.070110701107011\n",
            "1.03\n",
            "1.018140589569161\n",
            "1.0292275574112735\n",
            "1.0311890838206628\n",
            "1.042857142857143\n",
            "1.032258064516129\n",
            "1.0412844036697249\n",
            "1.0261780104712042\n",
            "1.0574712643678161\n",
            "1.0427046263345197\n",
            "1.0277536860364267\n",
            "1.0231404958677686\n",
            "1.0287581699346404\n",
            "1.0494699646643109\n",
            "1.0207253886010363\n",
            "1.0264244426094138\n",
            "1.0167714884696017\n",
            "1.032967032967033\n",
            "1.0302267002518892\n",
            "1.0204778156996588\n",
            "1.050314465408805\n",
            "1.0092807424593968\n",
            "1.047808764940239\n",
            "1.02570281124498\n",
            "1.0292134831460673\n",
            "1.063768115942029\n",
            "1.040983606557377\n",
            "1.0171428571428571\n",
            "1.0180995475113122\n",
            "1.0260223048327137\n",
            "1.0526735833998404\n",
            "1.1106719367588933\n",
            "1.0508474576271187\n",
            "1.021505376344086\n",
            "1.024390243902439\n",
            "1.0194174757281553\n",
            "1.048\n",
            "1.0\n",
            "1.039453717754173\n",
            "1.0344530577088717\n",
            "1.0217129071170084\n",
            "1.0460358056265984\n",
            "1.0182648401826484\n",
            "1.033096926713948\n",
            "1.032490974729242\n",
            "1.0338028169014084\n",
            "1.0238568588469186\n",
            "1.0341296928327646\n",
            "1.0358056265984654\n",
            "1.0757575757575757\n",
            "1.010752688172043\n",
            "1.0346820809248556\n",
            "1.0155642023346303\n",
            "1.0341296928327646\n",
            "1.0652482269503547\n",
            "1.0463320463320462\n",
            "1.0186046511627906\n",
            "1.0227272727272727\n",
            "1.041025641025641\n",
            "1.0387409200968523\n",
            "1.0520094562647755\n",
            "1.0340557275541795\n",
            "1.054054054054054\n",
            "1.0399201596806387\n",
            "1.0285714285714285\n",
            "1.0426439232409381\n",
            "1.0404040404040404\n",
            "1.0955414012738853\n",
            "1.0422535211267605\n",
            "1.0135685210312075\n",
            "1.051931602279924\n",
            "1.0869565217391304\n",
            "1.0464037122969838\n",
            "1.0483870967741935\n",
            "1.0505263157894738\n",
            "1.0320512820512822\n",
            "1.0446428571428572\n",
            "1.0475247524752476\n",
            "1.0260869565217392\n",
            "1.060747663551402\n",
            "1.0823970037453183\n",
            "1.0268620268620268\n",
            "1.0253164556962024\n",
            "1.0\n",
            "1.0346020761245676\n",
            "1.0714285714285714\n",
            "1.051044083526682\n",
            "1.0434782608695652\n",
            "1.0728744939271255\n",
            "1.0697050938337802\n",
            "1.0257648953301126\n",
            "1.0208333333333333\n",
            "1.0524781341107872\n",
            "1.013745704467354\n",
            "1.0606826801517066\n",
            "1.0417910447761194\n",
            "1.0345821325648414\n",
            "CROSS VAL METRICS:\n",
            "NB Accuracy: 0.22222222222222218\n",
            "NB Precision: 0.7515151515151516\n",
            "NB Recall: 0.8090909090909091\n",
            "NB F1: 0.7076190476190477\n",
            "DT Accuracy: 0.09999999999999999\n",
            "DT Precision: 0.8119878787878788\n",
            "DT Recall: 0.7666666666666667\n",
            "DT F1: 0.6621538461538461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N7gdgRrYeSO"
      },
      "source": [
        ""
      ],
      "execution_count": 60,
      "outputs": []
    }
  ]
}